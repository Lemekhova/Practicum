# Проект для «Викишоп» с BERT

## Статус проекта
Проект выполнен в полном объеме. Завершен.

## Данные

Набор данных с разметкой о токсичности.

- text - в нём содержит текст комментария
- toxic — целевой признак

## Задача

Заказчик — Интернет-магазину «Викишоп».

Цель: создать инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

Необходимо: обучить модель классифицировать комментарии на позитивные и негативные.

Необходимо построить модель со значением метрики качества F1 не меньше 0.75.

## Выводы
Для прогнозирования токсичности комментариев в работе была рассмотрена работа моделей Логистическая регрессия, Дерево решений и Случайный лес.

Предварительно текст был лемматизирован и очищен. Затем векторизирован и предобработан с помощью модели BERT. Обучение моделей производилось до применения BERT и после.
Стоит заметить, что предобработка с помощью BERT и дальнейшее предсказания производились на части данных, т.к. создание эмбедингов на полных данных на имеющихся мощностях компьютера занимает весьма продолжительное время. В связи с этим, с целью рассмотреть качество моделей с BERT в работе была рассмотрена выборка в 1000 элементов (создание эмбедингов заняла 42 мин).

Модели после подготовки признаков с помощью BERT обучаются в разы быстрее. Однако, при этом F1 мера моделей получается гораздо ниже. Скорее всего, это связано с тем, что данные для BERT взяты не полные.

## Используемые библиотеки
*Pandas*
*Nltk*
*Numpy*
*Re*
*Torch*
*Transformers*

## Используемые модели
*BERT*
*LogisticRegression*
*DecisionTreeClassifier*
*RandomForestClassifier*