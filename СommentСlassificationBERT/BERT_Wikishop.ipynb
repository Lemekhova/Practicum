{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подгтовим-признаки-для-работы-моделей-с-помощью-обычной-векторизации\" data-toc-modified-id=\"Подгтовим-признаки-для-работы-моделей-с-помощью-обычной-векторизации-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Подгтовим признаки для работы моделей с помощью обычной векторизации</a></span><ul class=\"toc-item\"><li><span><a href=\"#Модель-Логистической-регрессии\" data-toc-modified-id=\"Модель-Логистической-регрессии-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Модель Логистической регрессии</a></span></li><li><span><a href=\"#Модель-Дерево-решений\" data-toc-modified-id=\"Модель-Дерево-решений-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Модель Дерево решений</a></span></li><li><span><a href=\"#Модель-случайный-лес\" data-toc-modified-id=\"Модель-случайный-лес-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Модель случайный лес</a></span></li></ul></li><li><span><a href=\"#Подгтовим-признаки-для-работы-моделей-с-помощью-модели-BERT\" data-toc-modified-id=\"Подгтовим-признаки-для-работы-моделей-с-помощью-модели-BERT-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Подгтовим признаки для работы моделей с помощью модели BERT</a></span><ul class=\"toc-item\"><li><span><a href=\"#Модель-Логистической-регрессии\" data-toc-modified-id=\"Модель-Логистической-регрессии-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Модель Логистической регрессии</a></span></li><li><span><a href=\"#Модель-Дерево-решений\" data-toc-modified-id=\"Модель-Дерево-решений-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Модель Дерево решений</a></span></li><li><span><a href=\"#Модель-случайный-лес\" data-toc-modified-id=\"Модель-случайный-лес-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>Модель случайный лес</a></span></li></ul></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазину «Викишоп» нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Задача: обучить модель классифицировать комментарии на позитивные и негативные. \n",
    "\n",
    "Необходимо построить модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "Исходные данные: набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\blino\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re \n",
    "import transformers \n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import notebook\n",
    "\n",
    "nltk.download('punkt')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../../data/toxic_comments.csv')\n",
    "display(data)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В представленных данных наблюдается дисбалланс классов, поскольку классы делятся примерно в соотношении 90% и 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков не обнаружено. Можно подготавливать данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст: D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\n",
      "Очищенный и лемматизированный текст: D aww He match this background colour I m seemingly stuck with Thanks talk January UTC\n"
     ]
    }
   ],
   "source": [
    "# Лемматизируем и очистим текст\n",
    "corpus = data['text']\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Лемматизируем\n",
    "def lemm(text):\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "\n",
    "# Очистим текст\n",
    "def clear_text(text):\n",
    "    return \" \".join(re.sub(r'[^a-zA-Z ]', ' ', text).split())\n",
    "\n",
    "# Выведем на печать пример, чтобы проверить, что лемматизация работает\n",
    "print(\"Исходный текст:\", corpus[1])\n",
    "print(\"Очищенный и лемматизированный текст:\", clear_text(lemm(corpus[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проведем лемматизацию на всех данных\n",
    "corpus = data['text']\n",
    "data['lemm_text'] = data['text']\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "for i in range(len(data)):\n",
    "    data['lemm_text'][i] = clear_text(lemm(corpus[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D aww He match this background colour I m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man I m really not trying to edit war It s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I ca n t make any real suggestion on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Congratulations from me a well use the tool we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sorry if the word nonsense wa offensive to you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>Fair use rationale for Image Wonju jpg Thanks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bbq \\n\\nbe a man and lets discuss it-maybe ove...</td>\n",
       "      <td>0</td>\n",
       "      <td>bbq be a man and let discus it maybe over the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "      <td>Hey what is it talk What is it an exclusive gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Before you start throwing accusations and warn...</td>\n",
       "      <td>0</td>\n",
       "      <td>Before you start throwing accusation and warni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Oh, and the girl above started her arguments w...</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh and the girl above started her argument wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  toxic  \\\n",
       "0   Explanation\\nWhy the edits made under my usern...      0   \n",
       "1   D'aww! He matches this background colour I'm s...      0   \n",
       "2   Hey man, I'm really not trying to edit war. It...      0   \n",
       "3   \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4   You, sir, are my hero. Any chance you remember...      0   \n",
       "5   \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6        COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7   Your vandalism to the Matt Shirvington article...      0   \n",
       "8   Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9   alignment on this subject and which are contra...      0   \n",
       "10  \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...      0   \n",
       "11  bbq \\n\\nbe a man and lets discuss it-maybe ove...      0   \n",
       "12  Hey... what is it..\\n@ | talk .\\nWhat is it......      1   \n",
       "13  Before you start throwing accusations and warn...      0   \n",
       "14  Oh, and the girl above started her arguments w...      0   \n",
       "\n",
       "                                            lemm_text  \n",
       "0   Explanation Why the edits made under my userna...  \n",
       "1   D aww He match this background colour I m seem...  \n",
       "2   Hey man I m really not trying to edit war It s...  \n",
       "3   More I ca n t make any real suggestion on impr...  \n",
       "4   You sir are my hero Any chance you remember wh...  \n",
       "5   Congratulations from me a well use the tool we...  \n",
       "6        COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK  \n",
       "7   Your vandalism to the Matt Shirvington article...  \n",
       "8   Sorry if the word nonsense wa offensive to you...  \n",
       "9   alignment on this subject and which are contra...  \n",
       "10  Fair use rationale for Image Wonju jpg Thanks ...  \n",
       "11  bbq be a man and let discus it maybe over the ...  \n",
       "12  Hey what is it talk What is it an exclusive gr...  \n",
       "13  Before you start throwing accusation and warni...  \n",
       "14  Oh and the girl above started her argument wit...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подгтовим признаки для работы моделей с помощью обычной векторизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127656, 3)\n",
      "(31915, 3)\n"
     ]
    }
   ],
   "source": [
    "# Разобьем данные на тренировочную и тестовые выборки. Тестовую выборку определим в 50%\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Проверим размер полученных выборок\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразование в юникод здесь не нужно, поскольку представленный текст на английском языке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\blino\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Подготовим данные для моделей. Векторизуем текст.\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "corpus_train = train['lemm_text'].values\n",
    "corpus_test = test['lemm_text'].values\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "tf_idf_train = count_tf_idf.fit_transform(corpus_train)\n",
    "tf_idf_test = count_tf_idf.transform(corpus_test)\n",
    "\n",
    "train_target = train['toxic']\n",
    "test_target = test['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель Логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cреднее гармоническое полноты и точности на тренировочной выборке 0.8968982240675482\n",
      "Cреднее гармоническое полноты и точности на тестовой выборке 0.7640989399293286\n",
      "CPU times: total: 3.11 s\n",
      "Wall time: 3.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "1 + 1\n",
    "\n",
    "# Обучим модель Логистической регрессии\n",
    "model = LogisticRegression(C=5.852, class_weight='balanced', solver='liblinear')\n",
    "model.fit(tf_idf_train, train_target)\n",
    "\n",
    "train_predictions = model.predict(tf_idf_train)\n",
    "test_predictions = model.predict(tf_idf_test)\n",
    "\n",
    "# Рассчитаем F1 меру для модели Логистической регрессии\n",
    "print('Cреднее гармоническое полноты и точности на тренировочной выборке', f1_score(train_predictions, train_target))\n",
    "print('Cреднее гармоническое полноты и точности на тестовой выборке', f1_score(test_predictions, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 121, 'min_samples_leaf': 1, 'max_depth': 51}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=12345)\n",
    "model.fit(tf_idf_train, train_target)\n",
    "\n",
    "# Поиск лучших параметров модели\n",
    "parametrs = { 'max_depth': range (1, 100, 50),\n",
    "              'min_samples_leaf': range (1,130, 20),\n",
    "              'min_samples_split': range (1,130, 20)}\n",
    "grid = GridSearchCV(model,parametrs,cv = 3)\n",
    "grid = RandomizedSearchCV(model, parametrs, cv=5)\n",
    "grid.fit(tf_idf_train, train_target)\n",
    "\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cреднее гармоническое полноты и точности на тренировочной выборке 0.7582772543741588\n",
      "Cреднее гармоническое полноты и точности на тестовой выборке 0.7059856064595401\n",
      "CPU times: total: 25.3 s\n",
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "1 + 1\n",
    "\n",
    "# Обучим модель Дерево решений\n",
    "model = DecisionTreeClassifier(min_samples_split=121, min_samples_leaf=1, max_depth=51)\n",
    "model.fit(tf_idf_train, train_target)\n",
    "\n",
    "train_predictions = model.predict(tf_idf_train)\n",
    "test_predictions = model.predict(tf_idf_test)\n",
    "\n",
    "# Рассчитаем F1 меру для модели Дерево решений\n",
    "print('Cреднее гармоническое полноты и точности на тренировочной выборке', f1_score(train_predictions, train_target))\n",
    "print('Cреднее гармоническое полноты и точности на тестовой выборке', f1_score(test_predictions, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 10, 'max_depth': 121}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Поиск лучших параметров модели\n",
    "model = RandomForestClassifier(random_state=12345)\n",
    "model.fit(tf_idf_train, train_target)\n",
    "\n",
    "parametrs = { 'n_estimators': range (10, 100, 50),\n",
    "              'max_depth': range (1,130, 20), }\n",
    "grid = GridSearchCV(model,parametrs,cv = 3)\n",
    "grid = RandomizedSearchCV(model, parametrs, cv=5)\n",
    "grid.fit(tf_idf_train, train_target)\n",
    "\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cреднее гармоническое полноты и точности на тренировочной выборке 0.30144356955380575\n",
      "Cреднее гармоническое полноты и точности на тестовой выборке 0.1550997471199775\n",
      "CPU times: total: 1min\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "1 + 1\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=60, max_depth=81, random_state=12345)\n",
    "model.fit(tf_idf_train, train_target)\n",
    "\n",
    "train_predictions = model.predict(tf_idf_train)\n",
    "test_predictions = model.predict(tf_idf_test)\n",
    "\n",
    "# Рассчитаем F1 меру для модели Случайный лес\n",
    "print('Cреднее гармоническое полноты и точности на тренировочной выборке', f1_score(train_predictions, train_target))\n",
    "print('Cреднее гармоническое полноты и точности на тестовой выборке', f1_score(test_predictions, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подгтовим признаки для работы моделей с помощью модели BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтобы не создавать эмбеддинги слишком долго, возьмем из выборки только 1000 случайных элементов\n",
    "data_new = data.sample(1000).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем предобученную модель токанизатора\n",
    "bert_tokenizer_en = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Загружаем предобученную модель BERT\n",
    "model = transformers.BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токанизируем текст\n",
    "tokenized = data_new['text'].apply((lambda x: bert_tokenizer_en.encode(x, add_special_tokens=True, padding=True, truncation=True)))\n",
    "\n",
    "# Приведем длину токенов к единому размеру\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 512)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "np.array(padded).shape # Проверим размер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зададим маски\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32947126116b4d5fb5ada35daf545013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1h 58min 59s\n",
      "Wall time: 29min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "1 + 1\n",
    "\n",
    "# Попробовала с CPU\n",
    "\n",
    "from tqdm import notebook\n",
    "batch_size = 2 # для примера возьмем такой батч, где будет всего две строки датасета\n",
    "embeddings = [] \n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]).to(device) # закидываем тензор на GPU\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.to(device)\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy()) # перевод обратно на проц, чтобы в нумпай кинуть\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings\n",
    "        \n",
    "features = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соберём все эмбеддинги в матрицу признаков вызовов функции concatenate()\n",
    "features = np.concatenate(embeddings)\n",
    "\n",
    "target = data_new['toxic'] # Определим таргеты\n",
    "\n",
    "# Разобьем данные на тренировочную и тестовые выборки. Тестовую выборку определим в 50%\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель Логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cреднее гармоническое полноты и точности на тренировочной выборке 1.0\n",
      "Cреднее гармоническое полноты и точности на тестовой выборке 0.7142857142857143\n",
      "CPU times: total: 344 ms\n",
      "Wall time: 377 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "1 + 1\n",
    "\n",
    "# Опробуем предобработанные признаки с помощью BERT на модели Линейной регрессии\n",
    "model = LogisticRegression(C=5.852, class_weight='balanced', solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "train_predictions = model.predict(features_train)\n",
    "test_predictions = model.predict(features_test)\n",
    "\n",
    "print('Cреднее гармоническое полноты и точности на тренировочной выборке', f1_score(train_predictions, target_train))\n",
    "print('Cреднее гармоническое полноты и точности на тестовой выборке', f1_score(test_predictions, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 41, 'min_samples_leaf': 21, 'max_depth': 51}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Опробуем предобработанные признаки с помощью BERT на модели \n",
    "model = DecisionTreeClassifier(random_state=12345)\n",
    "model.fit(tf_idf_train, train_target)\n",
    "\n",
    "# Поиск лучших параметров модели\n",
    "parametrs = { 'max_depth': range (1, 100, 50),\n",
    "              'min_samples_leaf': range (1,130, 20),\n",
    "              'min_samples_split': range (1,130, 20)}\n",
    "grid = GridSearchCV(model,parametrs,cv = 3)\n",
    "grid = RandomizedSearchCV(model, parametrs, cv=5)\n",
    "grid.fit(tf_idf_train, train_target)\n",
    "\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cреднее гармоническое полноты и точности на тренировочной выборке 0.6666666666666666\n",
      "Cреднее гармоническое полноты и точности на тестовой выборке 0.32786885245901637\n",
      "CPU times: total: 1.06 s\n",
      "Wall time: 1.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "1 + 1\n",
    "\n",
    "model = DecisionTreeClassifier(min_samples_split=101, min_samples_leaf=1, max_depth=51)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "train_predictions = model.predict(features_train)\n",
    "test_predictions = model.predict(features_test)\n",
    "\n",
    "print('Cреднее гармоническое полноты и точности на тренировочной выборке', f1_score(train_predictions, target_train))\n",
    "print('Cреднее гармоническое полноты и точности на тестовой выборке', f1_score(test_predictions, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 60, 'max_depth': 21}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Опробуем предобработанные признаки с помощью BERT на модели Случайный лес\n",
    "model = RandomForestClassifier(random_state=12345)\n",
    "model.fit(tf_idf_train, train_target)\n",
    "\n",
    "# Поиск лучших параметров модели Случайный лес\n",
    "parametrs = { 'n_estimators': range (10, 100, 50),\n",
    "              'max_depth': range (1,130, 20), }\n",
    "grid = GridSearchCV(model,parametrs,cv = 3)\n",
    "grid = RandomizedSearchCV(model, parametrs, cv=5)\n",
    "grid.fit(features_train, target_train)\n",
    "\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cреднее гармоническое полноты и точности на тренировочной выборке 0.9221556886227544\n",
      "Cреднее гармоническое полноты и точности на тестовой выборке 0.3076923076923077\n",
      "CPU times: total: 109 ms\n",
      "Wall time: 132 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "1 + 1\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=10, max_depth=121, random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "train_predictions = model.predict(features_train)\n",
    "test_predictions = model.predict(features_test)\n",
    "\n",
    "print('Cреднее гармоническое полноты и точности на тренировочной выборке', f1_score(train_predictions, target_train))\n",
    "print('Cреднее гармоническое полноты и точности на тестовой выборке', f1_score(test_predictions, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для прогнозирования токсичности комментариев в работе была рассмотрена работа моделей Логистическая регрессия, Дерево решений и Случайный лес после векторизации текста и после предобработки с помощью модели BERT.\n",
    "\n",
    "Однако, стоит заметить, что предобработка с помощью BERT и дальнейшее предсказания производились на части данных, т.к. создание эмбедингов на полных данных на имеющихся мощностях компьютера занимает весьма продолжительное время (для примера, на выборке в 10000 элементов компьютер планировал формировать эмбендинги более 5 часов). В связи с этим, с целью рассмотреть качество моделей с BERT в работе была рассмотрена выборка в 1000 элементов (создание эмбедингов заняла 42 мин). \n",
    "\n",
    "Ниже представлена сводная сравнительная таблица итоговых показателей по моделям.\n",
    "\n",
    "Модели после подготовки признаков с помощью BERT обучаются в разы быстрее. Однако, при этом F1 мера моделей получается гораздо ниже. Возможно это связано с тем, что данные для BERT взяты не полные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>F1_train</th>\n",
       "      <th>F1_test</th>\n",
       "      <th>learn_time</th>\n",
       "      <th>F1_train_BERT</th>\n",
       "      <th>F1_test_BERT</th>\n",
       "      <th>learn_time_BERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.87 sec</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>212 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>26.4 sec</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>724 ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.19</td>\n",
       "      <td>49,2 sec</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.34</td>\n",
       "      <td>134 ms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   models  F1_train  F1_test learn_time  F1_train_BERT  \\\n",
       "0      LogisticRegression      0.90     0.76   2.87 sec           1.00   \n",
       "1  DecisionTreeClassifier      0.73     0.72   26.4 sec           0.25   \n",
       "2  RandomForestClassifier      0.32     0.19   49,2 sec           0.71   \n",
       "\n",
       "   F1_test_BERT learn_time_BERT  \n",
       "0          0.56          212 ms  \n",
       "1          0.10          724 ms  \n",
       "2          0.34          134 ms  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = ['LogisticRegression', 'DecisionTreeClassifier', 'RandomForestClassifier']\n",
    "\n",
    "F1_train = [0.9, 0.73, 0.32]\n",
    "F1_test = [0.76, 0.72, 0.19]\n",
    "learn_time = ['2.87 sec', '26.4 sec', '49,2 sec']\n",
    "\n",
    "F1_train_BERT = [1.0, 0.25, 0.71]\n",
    "F1_test_BERT = [0.56, 0.1, 0.34]\n",
    "learn_time_BERT =['212 ms', '724 ms', '134 ms']\n",
    "\n",
    "df = pd.DataFrame({'models': models,'F1_train': F1_train,'F1_test': F1_test, 'learn_time': learn_time,\n",
    "                   'F1_train_BERT': F1_train_BERT, 'F1_test_BERT': F1_test_BERT, 'learn_time_BERT': learn_time_BERT})\n",
    "\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
